# Data Model and Pipeline

## 1. Data Sources

The primary data source for `actualgamesearch.com` is the **Steam Web API** and the unofficial Steam Storefront API. The offline ETL pipeline will be responsible for collecting the following data:

*   **Game Metadata:** Titles, descriptions, developers, publishers, release dates, genres, etc.
*   **User Reviews:** User-submitted reviews, including the review text, language, and voting data.
*   **Visual Assets:** Header images and screenshots for each game.

## 2. Database Schemas

The system will utilize two databases: Cloudflare D1 for relational data and full-text search, and Cloudflare Vectorize for semantic search.

### 2.1. Cloudflare D1 (Metadata and FTS)

**Table: `games`**

| Column | Type | Description |
| :--- | :--- | :--- |
| `id` | INTEGER PRIMARY KEY | Internal ID |
| `steam_appid` | INTEGER UNIQUE | Steam Application ID |
| `title` | TEXT | Game Title |
| `description_corpus`| TEXT | Combined text (description + reviews) for FTS. |
| `genres` | TEXT (JSON array) | List of genres |
| `release_year` | INTEGER | Year of release |
| `header_image_url` | TEXT | URL for the header image |
| `developer` | TEXT | Game developer(s) |
| `publisher` | TEXT | Game publisher(s) |
| `nearest_neighbors` | TEXT | Pipe-separated list of related `steam_appid`s |

**Virtual Table: `games_fts`**

To enable full-text search, an FTS5 virtual table will be created:

```sql
CREATE VIRTUAL TABLE games_fts USING fts5(
    title,
    description_corpus,
    content='games',
    content_rowid='id'
);
```

### 2.2. Cloudflare Vectorize (Semantic Embeddings)

**Index: `game-embeddings-index`**

| Field | Type | Description |
| :--- | :--- | :--- |
| `id` | String | Corresponds to `games.id` from D1. |
| `vector` | Float Array | The embedding vector (e.g., 768 dimensions). |
| `metadata` | JSON | `{"steam_appid": 12345}` |

## 3. Embedding Strategy

To ensure consistency, the same embedding model will be used for both the offline pipeline and the online API.

*   **Model Selection:** A text embedding model available via **Cloudflare Workers AI** will be used (e.g., `@cf/baai/bge-base-en-v1.5`).
*   **Corpus Generation:** For each game, a rich text corpus will be generated by concatenating the official game description with the top N (e.g., 100-200) most relevant user reviews. Relevance will be determined using the "time-weighted resonance" logic from the legacy notebooks.
*   **Image Embeddings (Future):** For multimodal search, a CLIP or vision transformer model from Workers AI will be used to generate embeddings for game screenshots.

## 4. Offline Data Pipeline (ETL)

The ETL process will be implemented as a Python script running in a **Cloudflare Container**, orchestrated by a **Scheduled Worker** and a **Durable Object**.

### 4.1. ETL Workflow

1.  **Trigger:** A Scheduled Worker with a Cron Trigger initiates the ETL process.
2.  **Orchestration:** The Worker invokes a Durable Object, which manages the job state and starts the Cloudflare Container.
3.  **Execution (Python Container):**
    *   **Fetch:** Scrape and download raw data from the Steam APIs.
    *   **Transform:**
        *   Clean and normalize text using the `preprocess_text` function from the legacy notebooks.
        *   Filter reviews based on quality (e.g., minimum word count, not received for free).
        *   Calculate "time-weighted resonance" for reviews.
        *   Generate the text corpus for embedding.
    *   **Embed:**
        *   For each game, generate a vector embedding by calling the **Cloudflare Workers AI REST API**.
    *   **Nearest Neighbor Pre-computation:**
        *   Use an ANN library (e.g., Faiss) within the container to pre-calculate the K=20 nearest neighbors for each game.
    *   **Load:**
        *   Perform a bulk `INSERT OR REPLACE` into the D1 `games` table.
        *   Perform a bulk `upsert` into the Vectorize index.
    *   **Backup:** Upload a snapshot of the data to Cloudflare R2.
4.  **Completion:** The container script exits, and the container is automatically shut down.
